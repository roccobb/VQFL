{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "921df8f1-ba25-4a55-ad57-149a66c98f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn\n",
    "import torchquantum as tq\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.optim import Adam\n",
    "from torchquantum.measurement import expval_joint_analytical\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6dbb5575-5ed4-4b27-871d-a595b9e7cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_setting(setting):\n",
    "    folder = \"../exps\"\n",
    "    json_file = \"data_config.json\"\n",
    "    json_path = os.path.join(folder, setting, json_file)\n",
    "    with open(json_path, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    permutation_seed = config[\"permutation_seed\"]\n",
    "    test_size = config[\"test_size\"]\n",
    "    partition_seed = config[\"partition_seed\"]\n",
    "    n_class = config[\"n_class\"]\n",
    "    \n",
    "    data_tensors = config[\"data_tensors\"]\n",
    "    loaded_data_tensors = torch.load(data_tensors)\n",
    "    data_tr = loaded_data_tensors[\"data_tr\"]\n",
    "    label_tr = loaded_data_tensors[\"label_tr\"]\n",
    "    data_te = loaded_data_tensors[\"data_te\"]\n",
    "    label_te = loaded_data_tensors[\"label_te\"]\n",
    "\n",
    "    return permutation_seed, test_size, partition_seed, n_class, data_tr, label_tr, data_te, label_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14b84df3-ac86-4110-8499-0448cd09ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_dataloader(data_tr, label_tr, batch_size):\n",
    "    training_dataset = TensorDataset(data_tr, label_tr)\n",
    "    training_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "    return training_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7861b843-5a02-44c2-b08d-9a97698d9902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc769f1c-78a9-4e91-bf88-0e756a13054f",
   "metadata": {},
   "source": [
    "### Exp1: 10 classes, 8 clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2eaf22da-a55f-4f03-95eb-a68b98cd272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the expectations values to concat the clients' outputs\n",
    "class QNNsubModel(nn.Module):\n",
    "    def __init__(self, n_qubits=8, n_block=5, n_depth_per_block=1):\n",
    "        # params is numpy array\n",
    "        super().__init__()\n",
    "        self.n_wires = n_qubits\n",
    "        self.encoder_gates_x = ([tq.functional.rx] * self.n_wires + [tq.functional.ry] * self.n_wires)*2\n",
    "        self.n_block = n_block\n",
    "        self.n_depth_per_block = n_depth_per_block\n",
    "        params = np.random.rand( self.n_wires*self.n_depth_per_block*self.n_block*2)*math.pi\n",
    "        self.u_layers = tq.QuantumModuleList()\n",
    "        for j in range(self.n_depth_per_block*self.n_block):\n",
    "            for i in range(self.n_wires):\n",
    "                self.u_layers.append( tq.RX(has_params=True, trainable=True, init_params=params[i+(2*j)*self.n_wires]) )\n",
    "            for i in range(self.n_wires):\n",
    "                self.u_layers.append( tq.RY(has_params=True, trainable=True, init_params=params[i+(2*j+1)*self.n_wires]) )\n",
    "\n",
    "    def forward(self, x):\n",
    "        bsz, nx_features = x.shape\n",
    "        qdev = tq.QuantumDevice(\n",
    "            n_wires=self.n_wires, bsz = bsz, device=x.device, record_op=False\n",
    "        )\n",
    "        n_depth_per_block = self.n_depth_per_block\n",
    "        for d in range(self.n_block-1): # (2,4)\n",
    "            for k in range(n_depth_per_block):\n",
    "                for j in range(2*d*n_depth_per_block+2*k,2*d*n_depth_per_block+2*k+2):\n",
    "                    for i in range(self.n_wires):\n",
    "                        self.u_layers[i+j*self.n_wires](qdev, wires=i)\n",
    "                for i in range(self.n_wires):\n",
    "                    qdev.cz(wires=[i,(i+1)%self.n_wires])\n",
    "            # data encoding\n",
    "            #for j in range(2*d,2*d+1): # (0,2) (2,4)\n",
    "            for k in range(self.n_wires):\n",
    "                    #self.encoder_gates_x[k+j*self.n_wires](qdev, wires=k, params=x[:, (k+j*self.n_wires)])\n",
    "                index = k + d * self.n_wires\n",
    "                self.encoder_gates_x[index](qdev, wires=k, params=x[:, (index)])\n",
    "            for i in range(self.n_wires):\n",
    "                qdev.cz(wires=[i,(i+1)%self.n_wires])\n",
    "        for d in range(self.n_block-1,self.n_block): # (4,5)\n",
    "            for k in range(n_depth_per_block):\n",
    "                for j in range(2*d*n_depth_per_block+2*k,2*d*n_depth_per_block+2*k+2):\n",
    "                    for i in range(self.n_wires):\n",
    "                        self.u_layers[i+j*self.n_wires](qdev, wires=i)\n",
    "                if k==n_depth_per_block-1:\n",
    "                    break\n",
    "                for i in range(self.n_wires):\n",
    "                    qdev.cz(wires=[i,(i+1)%self.n_wires])\n",
    "\n",
    "        obs_list = [ expval_joint_analytical(qdev, \"I\"*i+Pauli+\"I\"*(self.n_wires-1-i)) for Pauli in [\"Z\"] for i in range(self.n_wires)]\n",
    "        ret = torch.stack(obs_list, dim=1)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44dadf8a-d1ff-463f-a846-613658c4e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QantumServerSubModel(nn.Module):\n",
    "    def __init__(self, n_qubits=8, n_block=5, n_depth_per_block=1):\n",
    "        # params is numpy array\n",
    "        super().__init__()\n",
    "        self.n_wires = n_qubits\n",
    "        self.encoder_gates_x = ([tq.functional.rx] * self.n_wires + [tq.functional.ry] * self.n_wires)*4\n",
    "        self.n_block = n_block\n",
    "        self.n_depth_per_block = n_depth_per_block\n",
    "        params = np.random.rand( self.n_wires*self.n_depth_per_block*self.n_block*2)*math.pi\n",
    "        self.u_layers = tq.QuantumModuleList()\n",
    "        for j in range(self.n_depth_per_block*self.n_block):\n",
    "            for i in range(self.n_wires):\n",
    "                self.u_layers.append( tq.RX(has_params=True, trainable=True, init_params=params[i+(2*j)*self.n_wires]) )\n",
    "            for i in range(self.n_wires):\n",
    "                self.u_layers.append( tq.RY(has_params=True, trainable=True, init_params=params[i+(2*j+1)*self.n_wires]) )\n",
    "\n",
    "    def forward(self, x):\n",
    "        bsz, nx_features = x.shape\n",
    "        qdev = tq.QuantumDevice(\n",
    "            n_wires=self.n_wires, bsz = bsz, device=x.device, record_op=False\n",
    "        )\n",
    "        n_depth_per_block = self.n_depth_per_block\n",
    "        for d in range(self.n_block-1): # (2,4)\n",
    "            for k in range(n_depth_per_block):\n",
    "                for j in range(2*d*n_depth_per_block+2*k,2*d*n_depth_per_block+2*k+2):\n",
    "                    for i in range(self.n_wires):\n",
    "                        self.u_layers[i+j*self.n_wires](qdev, wires=i)\n",
    "                for i in range(self.n_wires):\n",
    "                    qdev.cz(wires=[i,(i+1)%self.n_wires])\n",
    "            # data encoding\n",
    "            for j in range(2*d,2*d+2): # (0,2) (2,4)\n",
    "                for k in range(self.n_wires):\n",
    "                #for k in range(2):\n",
    "                    self.encoder_gates_x[k+j*self.n_wires](qdev, wires=k, params=x[:, (k+j*self.n_wires)])\n",
    "                    #index = k + j * 2\n",
    "                    #self.encoder_gates_x[index](qdev, wires=k, params=x[:, (index)])\n",
    "            for i in range(self.n_wires):\n",
    "                qdev.cz(wires=[i,(i+1)%self.n_wires])\n",
    "        for d in range(self.n_block-1,self.n_block): # (4,5)\n",
    "            for k in range(n_depth_per_block):\n",
    "                for j in range(2*d*n_depth_per_block+2*k,2*d*n_depth_per_block+2*k+2):\n",
    "                    for i in range(self.n_wires):\n",
    "                        self.u_layers[i+j*self.n_wires](qdev, wires=i)\n",
    "                if k==n_depth_per_block-1:\n",
    "                    break\n",
    "                for i in range(self.n_wires):\n",
    "                    qdev.cz(wires=[i,(i+1)%self.n_wires])\n",
    "\n",
    "        obs_list = [ expval_joint_analytical(qdev, \"I\"*i+Pauli+\"I\"*(self.n_wires-1-i)) for Pauli in [\"Z\", \"X\"] for i in range(n_class//2)]\n",
    "        ret = torch.stack(obs_list, dim=1)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "152a3059-151f-4a12-b7e8-6d98f4c6b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumServer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.coeff = coeff\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        #self.fc1 = nn.Linear(in_features=16*4, out_features=10)\n",
    "        self.q = QantumServerSubModel().to(device)\n",
    "        #self.q = QantumServerSubModel_96()\n",
    "\n",
    "    def forward(self, clients_outputs):\n",
    "        # result = sum(clients_outputs)\n",
    "        # result = result * self.coeff\n",
    "        # result = self.softmax(result)\n",
    "        concatenated_result = torch.cat(clients_outputs, dim=1)\n",
    "        #result = self.fc1(concatenated_result)\n",
    "        result = self.q(concatenated_result)\n",
    "        result = self.softmax(result)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ee85317-ece9-42f4-953a-b2655f089973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, label, clients_models, clients_optimizers, server_model, server_optimizer):\n",
    "    for i, client_model in enumerate(clients_models.values()):\n",
    "        client_model.train(mode=True)\n",
    "    server_model.train(mode=True)\n",
    "\n",
    "    for key, client_optimizer in clients_optimizers.items():\n",
    "        client_optimizer.zero_grad()\n",
    "    server_optimizer.zero_grad()\n",
    "\n",
    "    num_clients = len(clients_models)\n",
    "    features_per_client = data.shape[1] // num_clients\n",
    "    #features_per_client = 64\n",
    "    clients_data = [data[:, i * features_per_client:(i + 1) * features_per_client] for i in range(num_clients)]\n",
    "    print(clients_data[0].shape)\n",
    "\n",
    "    clients_outputs = []\n",
    "    for i, client_model in enumerate(clients_models.values()):\n",
    "        client_pred = client_model(clients_data[i])\n",
    "        # print(\"Client pred shape:\", client_pred.shape)\n",
    "        clients_outputs.append(client_pred)\n",
    "\n",
    "    #result = sum(clients_outputs)\n",
    "    # print(\"Client 1 outuput shape:\", clients_outputs[0].shape)\n",
    "    result = server_model(clients_outputs)\n",
    "    # result = clients_outputs[0] + clients_outputs[1] + clients_outputs[2] + clients_outputs[3]\n",
    "    # result = server_model(result)\n",
    "    # print(\"Result shape:\", result.shape)\n",
    "    loss = torch.nn.CrossEntropyLoss()(result, label)\n",
    "    acc = (result.argmax(axis=1) == label).sum().item() / len(label)\n",
    "    # acc = accuracy_score(y_tr, pred.argmax(axis=1).cpu().detach().numpy() )\n",
    "    print(f\"train loss: {loss.item():.5f}, train acc: {acc:.3f}\", end=' ')\n",
    "    loss.backward()\n",
    "    for key, client_optimizer in clients_optimizers.items():\n",
    "        client_optimizer.step()\n",
    "    server_optimizer.step()\n",
    "\n",
    "    return loss.item(), acc\n",
    "\n",
    "\n",
    "def test(data, label, clients_models, server_model):\n",
    "    num_clients = len(clients_models)\n",
    "    features_per_client = data.shape[1] // num_clients\n",
    "    #features_per_client = 64\n",
    "    clients_data = [data[:, i * features_per_client:(i + 1) * features_per_client] for i in range(num_clients)]\n",
    "\n",
    "    clients_outputs = []\n",
    "    for i, client_model in enumerate(clients_models.values()):\n",
    "        client_model.train(mode=False)\n",
    "        with torch.no_grad():\n",
    "            client_pred = client_model(clients_data[i])\n",
    "        clients_outputs.append(client_pred)\n",
    "\n",
    "    #result = sum(clients_outputs)\n",
    "    with torch.no_grad():\n",
    "        result = server_model(clients_outputs)\n",
    "    # result = clients_outputs[0] + clients_outputs[1] + clients_outputs[2] + clients_outputs[3]\n",
    "    # result = server_model(result)\n",
    "    loss = torch.nn.CrossEntropyLoss()(result, label)\n",
    "    acc = (result.argmax(axis=1) == label).sum().item() / len(label)\n",
    "    print(f\"test loss: {loss.item():.5f} test acc: {acc:.4f}\")\n",
    "    return loss.item(), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f591ad5f-a0f7-4de2-bc6a-b60430d27564",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_n_save_exp_8clients(setting_folder, save_path):\n",
    "\n",
    "    # Load data\n",
    "    permutation_seed, test_size, partition_seed, n_class, data_tr, label_tr, data_te, label_te = load_data_setting(setting_folder)\n",
    "    print(\"PERMUTATION SEED\", permutation_seed)\n",
    "    training_dataloader = create_training_dataloader(data_tr, label_tr, batch_size=32)\n",
    "\n",
    "    \n",
    "    # Hyperparameters\n",
    "    max_epochs = 2\n",
    "    lr = 0.002\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    \n",
    "    # Models' initialization\n",
    "    server_model = QuantumServer().to(device)\n",
    "    server_optimizer = Adam(server_model.parameters(), lr=lr)\n",
    "    client1_model = QNNsubModel().to(device)\n",
    "    client1_optimizer = Adam(client1_model.parameters(), lr=lr)\n",
    "    client2_model = QNNsubModel().to(device)\n",
    "    client2_optimizer = Adam(client2_model.parameters(), lr=lr)\n",
    "    client3_model = QNNsubModel().to(device)\n",
    "    client3_optimizer = Adam(client3_model.parameters(), lr=lr)\n",
    "    client4_model = QNNsubModel().to(device)\n",
    "    client4_optimizer = Adam(client4_model.parameters(), lr=lr)\n",
    "    client5_model = QNNsubModel().to(device)\n",
    "    client5_optimizer = Adam(client5_model.parameters(), lr=lr)\n",
    "    client6_model = QNNsubModel().to(device)\n",
    "    client6_optimizer = Adam(client6_model.parameters(), lr=lr)\n",
    "    client7_model = QNNsubModel().to(device)\n",
    "    client7_optimizer = Adam(client7_model.parameters(), lr=lr)\n",
    "    client8_model = QNNsubModel().to(device)\n",
    "    client8_optimizer = Adam(client8_model.parameters(), lr=lr)\n",
    "    \n",
    "    clients_models = {\"client1_model\": client1_model,\n",
    "                     \"client2_model\": client2_model,\n",
    "                     \"client3_model\": client3_model,\n",
    "                     \"client4_model\": client4_model,\n",
    "                     \"client5_model\": client5_model,\n",
    "                     \"client6_model\": client6_model,\n",
    "                     \"client7_model\": client7_model,\n",
    "                     \"client8_model\": client8_model}\n",
    "    clients_optimizers = {\"client1_optimizer\": client1_optimizer,\n",
    "                         \"client2_optimizer\": client2_optimizer,\n",
    "                         \"client3_optimizer\": client3_optimizer,\n",
    "                         \"client4_optimizer\": client4_optimizer,\n",
    "                         \"client5_optimizer\": client5_optimizer,\n",
    "                         \"client6_optimizer\": client6_optimizer,\n",
    "                         \"client7_optimizer\": client7_optimizer,\n",
    "                         \"client8_optimizer\": client8_optimizer}\n",
    "\n",
    "    \n",
    "    # Trainining and testing\n",
    "    all_tr_loss = []\n",
    "    all_test_loss = []\n",
    "    all_tr_acc = []\n",
    "    all_test_acc = []\n",
    "    for i_epoch in range(max_epochs):\n",
    "        epoch_loss = 0.0 \n",
    "        epoch_accuracy = 0.0 \n",
    "        total_samples = 0 \n",
    "        print(f\"Epoch {i_epoch}:\", end=\" \")\n",
    "        for batch_X, batch_y in training_dataloader:\n",
    "            print(batch_X.shape, batch_y.shape)\n",
    "            loss_tr, acc_tr = train(batch_X, batch_y, clients_models, clients_optimizers, server_model, server_optimizer)\n",
    "            batch_size = batch_X.size(0)\n",
    "            epoch_loss += loss_tr * batch_size  # Scale loss by batch size\n",
    "            epoch_accuracy += acc_tr * batch_size  # Scale accuracy by batch size\n",
    "            total_samples += batch_size  # Update sample count\n",
    "        epoch_loss /= total_samples\n",
    "        epoch_accuracy /= total_samples\n",
    "        print(f\"Training loss:{epoch_loss:.4f} Training acc:{epoch_accuracy:.4f}\")\n",
    "        loss_test, acc_test = test(data_te, label_te, clients_models, server_model)\n",
    "        all_tr_loss.append(epoch_loss)\n",
    "        all_test_loss.append(loss_test)\n",
    "        all_tr_acc.append(epoch_accuracy)\n",
    "        all_test_acc.append(acc_test)\n",
    "\n",
    "    \n",
    "    # Save models & parameters\n",
    "    models_tensors_path = save_path+\"/\"+\"models_tensors.pth\"\n",
    "    torch.save({\n",
    "        \"client1_model\": clients_models[\"client1_model\"].state_dict(),\n",
    "        \"client2_model\": clients_models[\"client2_model\"].state_dict(),\n",
    "        \"client3_model\": clients_models[\"client2_model\"].state_dict(),\n",
    "        \"client4_model\": clients_models[\"client2_model\"].state_dict(),\n",
    "        \"client5_model\": clients_models[\"client2_model\"].state_dict(),\n",
    "        \"client6_model\": clients_models[\"client2_model\"].state_dict(),\n",
    "        \"client7_model\": clients_models[\"client2_model\"].state_dict(),\n",
    "        \"client8_model\": clients_models[\"client2_model\"].state_dict(),\n",
    "        \"server_model\": server_model.state_dict(),\n",
    "    }, models_tensors_path)\n",
    "    \n",
    "    params = {\n",
    "        \"permutation_seed\": permutation_seed, \n",
    "        \"test_size\": test_size, \n",
    "        \"partition_seed\": partition_seed,\n",
    "        \"n_class\": n_class,\n",
    "        \"all_tr_loss\": all_tr_loss, \n",
    "        \"all_test_loss\": all_test_loss, \n",
    "        \"all_tr_acc\": all_tr_acc, \n",
    "        \"all_test_acc\": all_test_acc,\n",
    "        \"models_tensors\": models_tensors_path\n",
    "    }\n",
    "    \n",
    "    exp_path = save_path+\"/\"+\"exp.json\"\n",
    "    with open(exp_path, \"w\") as f:\n",
    "        json.dump(params, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cfb0de14-c3c4-4ba0-8909-82b4c3e0fde3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERMUTATION SEED 42\n",
      "Epoch 0: torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30984, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30361, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30355, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29577, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.31098, train acc: 0.031 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30721, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30266, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30255, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30789, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30611, train acc: 0.031 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30503, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30406, train acc: 0.031 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29863, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30967, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30110, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29919, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30523, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30230, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30293, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30937, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30136, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30579, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29650, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30772, train acc: 0.031 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30897, train acc: 0.031 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30565, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30371, train acc: 0.000 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30702, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30535, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29707, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30549, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30858, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30778, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30591, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30226, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30215, train acc: 0.188 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30440, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29769, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30672, train acc: 0.156 torch.Size([26, 256]) torch.Size([26])\n",
      "torch.Size([26, 32])\n",
      "train loss: 2.29662, train acc: 0.192 Training loss:2.3041 Training acc:0.0965\n",
      "test loss: 2.30141 test acc: 0.1097\n",
      "Epoch 1: torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30053, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30488, train acc: 0.188 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29863, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30272, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30297, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30674, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29760, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29822, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30041, train acc: 0.188 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30242, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29484, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30706, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29409, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30061, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29280, train acc: 0.188 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30281, train acc: 0.188 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29665, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29733, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29877, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29549, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30051, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29508, train acc: 0.219 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30270, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29184, train acc: 0.219 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30215, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30296, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29735, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30439, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29500, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30236, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29764, train acc: 0.188 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29589, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29761, train acc: 0.188 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29911, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29354, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30062, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29308, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30413, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29870, train acc: 0.156 torch.Size([26, 256]) torch.Size([26])\n",
      "torch.Size([26, 32])\n",
      "train loss: 2.30204, train acc: 0.077 Training loss:2.2993 Training acc:0.1397\n",
      "test loss: 2.29764 test acc: 0.1317\n",
      "PERMUTATION SEED 43\n",
      "Epoch 0: torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30609, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29942, train acc: 0.031 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30142, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30764, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29545, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30412, train acc: 0.031 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30043, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30528, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30525, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.31766, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29923, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30222, train acc: 0.031 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30749, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30760, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30384, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30631, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30167, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29722, train acc: 0.031 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29891, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30976, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29289, train acc: 0.188 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29808, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30493, train acc: 0.000 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30149, train acc: 0.031 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30122, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29929, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30696, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29709, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29646, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29741, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29423, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30402, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.31225, train acc: 0.000 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29821, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29776, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30626, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29692, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29542, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29990, train acc: 0.094 torch.Size([26, 256]) torch.Size([26])\n",
      "torch.Size([26, 32])\n",
      "train loss: 2.30165, train acc: 0.038 Training loss:2.3020 Training acc:0.0801\n",
      "test loss: 2.29897 test acc: 0.0972\n",
      "Epoch 1: torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29517, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29702, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30203, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30121, train acc: 0.031 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30270, train acc: 0.031 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29085, train acc: 0.219 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30390, train acc: 0.031 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.28908, train acc: 0.188 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30621, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.28813, train acc: 0.188 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29691, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29183, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29322, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30721, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30470, train acc: 0.031 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29350, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30073, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29591, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29330, train acc: 0.250 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29235, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29960, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30008, train acc: 0.031 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29231, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29707, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.28884, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.28911, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30327, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29249, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29680, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29781, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.28876, train acc: 0.188 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29824, train acc: 0.125 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29272, train acc: 0.188 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.30279, train acc: 0.062 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29157, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29537, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29627, train acc: 0.156 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.29514, train acc: 0.094 torch.Size([32, 256]) torch.Size([32])\n",
      "torch.Size([32, 32])\n",
      "train loss: 2.28955, train acc: 0.125 torch.Size([26, 256]) torch.Size([26])\n",
      "torch.Size([26, 32])\n",
      "train loss: 2.28716, train acc: 0.077 Training loss:2.2961 Training acc:0.1138\n",
      "test loss: 2.29364 test acc: 0.1191\n"
     ]
    }
   ],
   "source": [
    "settings = [\"Setting_1\", \"Setting_2\"]\n",
    "root = \"../exps\"\n",
    "\n",
    "for setting in settings:\n",
    "    path = os.path.join(root, setting)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    run_n_save_exp_8clients(setting, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da32f3f-14dc-44c8-98f2-2022ba3e21aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disq",
   "language": "python",
   "name": "disq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
